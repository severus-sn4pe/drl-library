{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8e6bd-610a-45f1-ae52-8521bf57f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta, date, datetime\n",
    "import shutil\n",
    "import time\n",
    "from config import crypto\n",
    "from config import general as config\n",
    "from finrl.meta.env_custom.random_init import RandomInit\n",
    "from lib.drl import data_split, train, test, get_model_params\n",
    "from lib.support import check_run_directory_structure, get_run_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444cb4e-e1dd-4f54-9933-89df19959f0c",
   "metadata": {},
   "source": [
    "# Retrain Short\n",
    "changes\n",
    "* skipping first iteration to have to save dataset as the ensemble strategy\n",
    "* first iteration is also retrained before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078f83e-4024-489d-a14c-b55521f07d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_windows(res, iteration: int = 0):\n",
    "    start_train = datetime.strptime(\"11.05.2021\", \"%d.%m.%Y\") \n",
    "    start_date = datetime.strptime(\"25.05.2022\", \"%d.%m.%Y\")\n",
    "    iterations = []\n",
    "    if iteration >= crypto.VALIDATION_ITERATIONS:\n",
    "        raise ValueError(f\"max allowed iteration is {crypto.VALIDATION_ITERATIONS - 1}, but {iteration} was provided\")\n",
    "    for i in range(crypto.VALIDATION_ITERATIONS):\n",
    "        end_date = start_date + timedelta(days=27, hours=23, minutes=59, seconds=59)\n",
    "        end_train = start_train + timedelta(days=378, hours=23, minutes=59, seconds=59)\n",
    "        iterations.append({'train_start': start_train, 'train_end': end_train, 'test_start': start_date, 'test_end': end_date})\n",
    "        # print(f\"{i:02} | train: {start_train} - {end_train}  | trade: start: {start_date} end: {end_date}\")\n",
    "        start_date = start_date + timedelta(days=28)\n",
    "        start_train = start_train + timedelta(days=28)\n",
    "    iterations = pd.DataFrame(iterations)\n",
    "    iterations.iloc[6]['test_end'] = '2022-12-01 23:59:59'\n",
    "    intraday_hours = '' if res == '1d' else ' %X'\n",
    "    moved_it = iteration + 1\n",
    "    window = {\n",
    "        \"train_start\": iterations.iloc[moved_it]['train_start'].strftime(f'%Y-%m-%d{intraday_hours}'),\n",
    "        \"train_end\": iterations.iloc[moved_it]['train_end'].strftime('%Y-%m-%d %X'),\n",
    "        \"test_start\": iterations.iloc[moved_it]['test_start'].strftime(f'%Y-%m-%d{intraday_hours}'),\n",
    "        \"test_end\": iterations.iloc[moved_it]['test_end'].strftime('%Y-%m-%d %X'),\n",
    "    }\n",
    "    return window\n",
    "\n",
    "def get_datasets(iteration, res = '1d'):\n",
    "    dataset_windows = get_dataset_windows(res, iteration)\n",
    "    # loading dataset\n",
    "    df = pd.read_csv(f\"{config.DATA_SAVE_DIR}/thesis/crypto_{res}_plus.csv\", index_col=0)\n",
    "    train_df = data_split(df, dataset_windows['train_start'], dataset_windows['train_end'])\n",
    "    test_df = data_split(df, dataset_windows['test_start'], dataset_windows['test_end'])\n",
    "    print(f\"train {train_df.shape} start: {train_df.iloc[0]['date']} end: {train_df.iloc[-1]['date']}\")\n",
    "    print(f\"test  {test_df.shape} start: {test_df.iloc[0]['date']} end: {test_df.iloc[-1]['date']}\")\n",
    "    return train_df, test_df\n",
    "\n",
    "def load_last_state(iteration_results_prefix):\n",
    "    state_file = pd.read_csv(f\"{iteration_results_prefix}_state.csv\", index_col=0)\n",
    "    last_state = state_file.iloc[-1]\n",
    "    num_shares = last_state[[x+\"_amount\" for x in TICKER_NAMES]].tolist()\n",
    "    cash = last_state['cash']\n",
    "    print(f\"cash          : {cash}\")\n",
    "    print(f\"NumStockShares: {num_shares}\")\n",
    "    return cash, num_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f291a1-5b5c-4587-b2dc-498d54ebb020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "ROOT_DIR = '.'\n",
    "# check_directory_structure(ROOT_DIR)\n",
    "STRATEGY_NAME = \"cs_eval\"\n",
    "# MODEL_NAME, CFG_ID = \"PPO\", \"V208\"\n",
    "MODEL_NAME, CFG_ID = \"A2C\", \"V221\"\n",
    "# MODEL_NAME, CFG_ID = \"TD3\", \"V214\"\n",
    "# NAME_SUFFIX = \"12H_short\" # A2C \"1D_260M\" \"12H_600M\" \"6H_550M\" \"1H_240M\"\n",
    "# NAME_SUFFIX = \"12H_600M\" # PPO \"1D_180M\" \"12H_600M\" \"6H_550M\" \"1H_200M\"\n",
    "NAME_SUFFIX = \"1D_mini_200\" # TD3 \"1D_18M\" \"12H_54M\" \"6H_54M\" \"1H_42M\"\n",
    "RES = '1d'\n",
    "\n",
    "MODEL_DIR = f\"{ROOT_DIR}/{config.TRAINED_MODEL_DIR}/{STRATEGY_NAME}\"\n",
    "TENSORBOARD_DIR = f\"{ROOT_DIR}/{config.TENSORBOARD_LOG_DIR}/{STRATEGY_NAME}\" # No logging for eval runs\n",
    "\n",
    "INITIAL_MODEL = f\"{ROOT_DIR}/trained_models/final_trained/A2C_1D_200M\"\n",
    "INITIAL_AMOUNT = 1_000_000\n",
    "\n",
    "SAVE_MODEL_PATH = f\"{ROOT_DIR}/trained_models/{STRATEGY_NAME}\"\n",
    "\n",
    "if RES == '6h':\n",
    "    RETRAIN_TIMESTEPS = 76_000 if MODEL_NAME == \"TD3\" else 758_000\n",
    "elif RES == '12h':\n",
    "    RETRAIN_TIMESTEPS = 76_000 if MODEL_NAME == \"TD3\" else 758_000\n",
    "elif RES == '1d':\n",
    "    RETRAIN_TIMESTEPS = 76_000 if MODEL_NAME == \"TD3\" else 758_000\n",
    "elif RES == '1h':\n",
    "    RETRAIN_TIMESTEPS = 230_000 if MODEL_NAME == \"TD3\" else 910_000\n",
    "else:\n",
    "    RETRAIN_TIMESTEPS = 5_000 if MODEL_NAME == \"TD3\" else 50_000\n",
    "\n",
    "RETRAIN_TIMESTEPS = 2000 if MODEL_NAME == \"TD3\" else 5000\n",
    "print(f\"Retrain Timesteps={RETRAIN_TIMESTEPS}\")\n",
    "\n",
    "MODEL_PARAMS = get_model_params(MODEL_NAME, CFG_ID)\n",
    "\n",
    "RUN_CONFIG = \"EVAL\"\n",
    "RUN_NAME_BASE = f\"{RUN_CONFIG}_{MODEL_NAME}_{CFG_ID}_{get_run_timestamp()}_{NAME_SUFFIX}\"\n",
    "\n",
    "BASE_RESULTS_DIR = f\"{ROOT_DIR}/{config.RESULTS_DIR}/{STRATEGY_NAME}/{MODEL_NAME}/{RUN_NAME_BASE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92dab6-e899-4274-b6b6-0f448fa4fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_datasets(0, RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1aaeb9-69a3-4d37-9abf-db75d47af477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrain_start = time.time()\n",
    "for iteration in range(crypto.VALIDATION_ITERATIONS-1):\n",
    "    print(f\"\\nIteration {iteration} / {crypto.VALIDATION_ITERATIONS - 2}\")\n",
    "    print(f\"---------------------------------\")\n",
    "\n",
    "    df_train, df_test = get_datasets(iteration, RES)\n",
    "    TICKER_NAMES = df_test.tic.unique().tolist()\n",
    "\n",
    "    stock_dimension = len(df_train.tic.unique())\n",
    "    state_space = 1 + 2 * stock_dimension + len(crypto.INDICATORS_PLUS) * stock_dimension\n",
    "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "    RUN_NAME = f\"{RUN_NAME_BASE}_iter{iteration}\"\n",
    "    SAVE_MODEL_NAME = f\"{MODEL_DIR}/{STRATEGY_NAME}_{MODEL_NAME}_{RUN_NAME}\"\n",
    "    RESULTS_FILE_PREFIX = f\"{BASE_RESULTS_DIR}/{MODEL_NAME}_{RUN_NAME}\"\n",
    "    PREVIOUS_RESULTS_PREFIX = f\"{BASE_RESULTS_DIR}/{MODEL_NAME}_{RUN_NAME_BASE}_iter{iteration-1}\"\n",
    "\n",
    "    if iteration == 0:\n",
    "        LOAD_MODEL_NAME = f\"{INITIAL_MODEL}\"\n",
    "        iteration_start_amount = INITIAL_AMOUNT\n",
    "        num_stock_shares = [0] * stock_dimension\n",
    "        do_retrain = True\n",
    "    else:\n",
    "        LOAD_MODEL_NAME = f\"{MODEL_DIR}/{STRATEGY_NAME}_{MODEL_NAME}_{RUN_NAME_BASE}_iter{iteration-1}\"\n",
    "        iteration_start_amount, num_stock_shares = load_last_state(PREVIOUS_RESULTS_PREFIX)\n",
    "        do_retrain = True\n",
    "\n",
    "    ENV_KWARGS = {\n",
    "        \"hmax\": 10_000,\n",
    "        \"initial_amount\": iteration_start_amount,\n",
    "        \"num_stock_shares\": num_stock_shares,\n",
    "        \"buy_cost_pct\": [0.001] * stock_dimension,\n",
    "        \"sell_cost_pct\": [0.001] * stock_dimension,\n",
    "        \"state_space\": state_space,\n",
    "        \"stock_dim\": stock_dimension,\n",
    "        \"tech_indicator_list\": crypto.INDICATORS_PLUS,\n",
    "        \"action_space\": stock_dimension,\n",
    "        \"print_verbosity\": 1e6,\n",
    "        \"reward_scaling\": 1e-6,\n",
    "        \"make_plots\": False,\n",
    "        \"mode\": \"train\",\n",
    "        \"strategy_name\": STRATEGY_NAME,\n",
    "        \"run_name\": RUN_NAME,\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"random_init\": RandomInit(random_init=False, always=False, mod=500, start=100, end=300)\n",
    "    }\n",
    "\n",
    "    print(f\"Using Model {MODEL_NAME} as {RUN_NAME} with params={MODEL_PARAMS}\")\n",
    "    print(f\"Retrain={do_retrain}\")\n",
    "    print(f\"Load model from {LOAD_MODEL_NAME}\")\n",
    "    print(f\"Save model to   {SAVE_MODEL_NAME}\")\n",
    "    print(f\"Save results to {RESULTS_FILE_PREFIX}\")\n",
    "\n",
    "    check_run_directory_structure(ROOT_DIR, config.RESULTS_DIR, STRATEGY_NAME, MODEL_NAME, RUN_NAME_BASE)\n",
    "\n",
    "    settings = {\n",
    "        \"total_timesteps\": RETRAIN_TIMESTEPS,\n",
    "        \"retrain_existing_model\": do_retrain,\n",
    "        \"previous_model_name\": LOAD_MODEL_NAME,\n",
    "        \"tensorboard_log\": TENSORBOARD_DIR,\n",
    "        \"env_kwargs\": ENV_KWARGS,\n",
    "        \"model_params\": MODEL_PARAMS,\n",
    "        \"save_model\": True,\n",
    "        \"target_model_filename\": SAVE_MODEL_NAME,\n",
    "        \"file_prefix\": RESULTS_FILE_PREFIX\n",
    "    }\n",
    "    \n",
    "    if do_retrain:\n",
    "        print(f\"Retraining on Iteration {iteration}\")\n",
    "        trained = train(df_train, ENV_KWARGS, settings)\n",
    "    else:\n",
    "        print(f\"Skipping Re-Train for iteration {iteration}\")\n",
    "        shutil.copyfile(LOAD_MODEL_NAME+\".zip\", SAVE_MODEL_NAME+\".zip\")\n",
    "    \n",
    "    test(df_test, ENV_KWARGS, settings, deterministic=True)\n",
    "    \n",
    "retrain_end = time.time()\n",
    "print(f\"done all in {retrain_end - retrain_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f5977-22a7-4925-b76a-12a31b4fd472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06401d16-d072-447c-a47a-357ca21dfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_fix(negative=False):\n",
    "    hours = 24\n",
    "    if RES == '6h':\n",
    "        hours = 6\n",
    "    if RES == '12h':\n",
    "        hours = 12\n",
    "    if RES == '1h':\n",
    "        hours = 1\n",
    "    if negative:\n",
    "        hours *= -1\n",
    "    return timedelta(hours=hours)\n",
    "\n",
    "def get_time_formatter():\n",
    "    return \"%Y-%m-%d\" if RES == '1d' else \"%Y-%m-%d %X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c944da4e-95f3-415e-be94-6bb21fac897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat separate actions files from each iteration into one file for the whole run\n",
    "actions = pd.DataFrame()\n",
    "for it in range(crypto.VALIDATION_ITERATIONS-1):\n",
    "    results_base = f\"{BASE_RESULTS_DIR}/{MODEL_NAME}_{RUN_NAME_BASE}_iter{it}\"\n",
    "    df_actions_iter = pd.read_csv(f\"{results_base}_actions.csv\")\n",
    "    \n",
    "    # add last day for each iteration \n",
    "    last_date = (pd.to_datetime(df_actions_iter.iloc[-1]['date'])+ get_delta_fix()).strftime(get_time_formatter())\n",
    "    last_row = pd.DataFrame([[last_date] + [0] * stock_dimension + [-1] * stock_dimension])\n",
    "    last_row.columns = df_actions_iter.columns\n",
    "    df_actions_iter = pd.concat([df_actions_iter, last_row])\n",
    "    df_actions_iter['iteration'] = it\n",
    "    if actions.empty:\n",
    "        actions = df_actions_iter\n",
    "    else:\n",
    "        actions = pd.concat([actions, df_actions_iter])\n",
    "    # print(results_base)\n",
    "    \n",
    "actions = actions.reset_index(drop=True)\n",
    "actions.to_csv(f\"{BASE_RESULTS_DIR}/all_actions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960e97c-2f4a-4f4e-9abc-97b7839220c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat separate state files from each iteration into one file for the whole run\n",
    "states = pd.DataFrame()\n",
    "for it in range(crypto.VALIDATION_ITERATIONS-1):\n",
    "    results_base = f\"{BASE_RESULTS_DIR}/{MODEL_NAME}_{RUN_NAME_BASE}_iter{it}\"\n",
    "    df_state_iter = pd.read_csv(f\"{results_base}_state.csv\", index_col=0)\n",
    "    \n",
    "    df_state_iter['date'] = df_state_iter.index\n",
    "    df_state_iter = df_state_iter.reset_index(drop=True)\n",
    "    df_state_iter.loc[0, 'date'] = (pd.to_datetime(df_state_iter.loc[1]['date'])+ get_delta_fix(negative=True)).strftime(get_time_formatter())\n",
    "    df_state_iter = df_state_iter.set_index('date', drop=True)\n",
    "    df_state_iter['iteration'] = it\n",
    "    \n",
    "    if states.empty:\n",
    "        states = df_state_iter\n",
    "    else:\n",
    "        states = pd.concat([states, df_state_iter])\n",
    "    # print(results_base)\n",
    "    \n",
    "# states = states.reset_index(drop=True)\n",
    "# states.index.rename(\"date\", inplace=True)\n",
    "states.to_csv(f\"{BASE_RESULTS_DIR}/all_state.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc97f3-0395-45c7-a978-b28ba5fd7f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f1a54-4fa3-40b0-9855-14e5fb33c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
